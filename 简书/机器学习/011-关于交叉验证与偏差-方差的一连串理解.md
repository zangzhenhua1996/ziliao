# 关于交叉验证与偏差/方差的一连串理解

 在机器学习训练模型时,对于数据集的划分其实是很重要的一个步骤.如果数据集划分出现问题,那么将会导致**模型过拟合(over fitting)或者欠拟合(under fitting)**.比如一次苹果品质判断模型训练中,刚好把具有斑点属性的好苹果全部划分到了train_data中,那么这次训练会由此导致过拟合的发生.

##### 那么如何更好地评估模型,从而根据评估结果进行模型判断呢?

`当然解决方案就是采用鼎鼎大名的K折交叉验证的方法.`

![image](https://upload-images.jianshu.io/upload_images/13777601-c578de8d6bbb13fc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/761/format/webp)

* * *

**在K折交叉验证中也存在一个问题,k如何取值?** 
*  k取值越大,即样本被划分用来训练的次数也就越多,保证了充分利用所有的样本.
*  带来的后果是由偏差bias带来的泛化误差降低,
* 由方差variance带来的泛化误差增加,同时还增加了计算量.总的来说就是过拟合(over fitting).
*  k值取得越小,即样本被划分用来训练的次数也就越少,没有保证样本被充分利用,此时,模型还没有学到足够多的信息.
* 带来的后果是由偏差bias带来的泛化误差增加,
* 由方差variance带来的泛化误差降低.总的来说就是欠拟合(under fitting).
> 根据经验,k一般取5或者10.

* * *

**偏差和反差又是什么呢?**
一张图就能看懂.

![image](https://upload-images.jianshu.io/upload_images/13777601-f219d695a34e6077.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/720/format/webp)

 偏差(bias)衡量的是模型对于训练数据的拟合程度(欠拟合是导致偏差的主要原因偏差越大,即训练的结果离真实样本就差远):

*   偏差过于低,仅代表对于训练数据的完美拟合,意味着模型十分复杂,已经过拟合(overfitting).一旦数据有任何的风吹草动,模型就会跟着发生显著变化,说明模型并不具有普适性,已经过于复杂了.

*   偏差越高说明模型对于训练数据的拟合还不到位,模型还过于简陋,属于欠拟合.导致这一情况发生的主要原因一般是对问题本身的假设不正确(例如二阶多项式回归拟合的问题,采用了一阶线性回归进行解决),亦或者是对于特征的选取出现问题(例如预测学生成绩,选用的特征却是学生名字).

 方差(variance)描述的是训练模型在测试集上的表现,即主要是泛化性能的体现,
* 方差越大说明模型越复杂越是过拟合,容易受到扰动. 因此,要求variance越小越好.为了降低方差,就需要简化模型,减少模型的参数,但是这样又容易欠拟合(under fitting).
>  因此可以发现偏差和方差是不可能同时最优的,只能尽量选择出泛化误差Error最小的组合,因为泛化Error = Bias + Variance.

![image](https://upload-images.jianshu.io/upload_images/13777601-d51133bed1c11ebe.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp)

有一些算法天生就是高方差的算法:KNN
通常来说,非参数学习通常都是高方差算法.因为模型对训练数据非常敏感.

有一些算法天生就是高偏差算法:线性回归
参数学习通常都是高偏差算法.因为选取时模型本身具有极强的假设性.

但是,大多数算法具有相应的参数,可以调整偏差和方差.例如KNN中的k和线性回归中的特征的阶数.

机器学习的主要挑战,来自于方差! 因为过拟合问题是模型训练中最常见的问题.

解决高方差的手段:

*   降低模型复杂度 : 防止过拟合
*   减少数据维度,降噪 : 尽量减少算法学习到的噪音信息
*   增加样本数目 : 算法模型太过复杂时,必要的参数过多,但是样本数目太少,不足以学习到最优的参数.
*   使用验证集 : 增加样本拆分数量,综合评价模型.
*   模型正则化: 最常见也是最重要的限制模型复杂程度的手段.

参考:
[https://www.zhihu.com/question/27068705](https://links.jianshu.com/go?to=https%3A%2F%2Fwww.zhihu.com%2Fquestion%2F27068705)
