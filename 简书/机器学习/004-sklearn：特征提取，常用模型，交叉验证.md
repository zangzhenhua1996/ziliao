è¿™ä¸€ç¯‡ï¼Œæˆ‘ä»¬å°†å¯¹sklearnä¸­æœ‰å…³ç‰¹å¾æå–ï¼Œå¸¸ç”¨æ¨¡å‹è¿›è¡Œè®²è§£ã€‚
ä¸»è¦å†…å®¹åŒ…æ‹¬ï¼š
1.PCAç®—æ³•
2.LDAç®—æ³•
3.çº¿æ€§å›å½’
4.é€»è¾‘å›å½’
5.æœ´ç´ è´å¶æ–¯
6.å†³ç­–æ ‘
7.SVM
8.ç¥ç»ç½‘ç»œ
9.KNNç®—æ³•
æ˜¯ä¸æ˜¯æ„Ÿè§‰å¹²è´§æ»¡æ»¡å•Šï¼Let's get moving!!!

## ç‰¹å¾æå–

æˆ‘ä»¬è·å–çš„æ•°æ®ä¸­å¾ˆå¤šæ•°æ®å¾€å¾€æœ‰å¾ˆå¤šç»´åº¦ï¼Œä½†å¹¶ä¸æ˜¯æ‰€æœ‰çš„ç»´åº¦éƒ½æ˜¯æœ‰ç”¨çš„ï¼Œæœ‰æ„ä¹‰çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬è¦å°†å¯¹ç»“æœå½±å“è¾ƒå°çš„ç»´åº¦èˆå»ï¼Œä¿ç•™å¯¹ç»“æœå½±å“è¾ƒå¤§çš„ç»´åº¦ã€‚
PCAï¼ˆä¸»æˆåˆ†åˆ†æï¼‰ä¸LDAï¼ˆçº¿æ€§è¯„ä»·åˆ†æï¼‰æ˜¯ç‰¹å¾æå–çš„ä¸¤ç§ç»å…¸ç®—æ³•ã€‚PCAä¸LDAæœ¬è´¨ä¸Šéƒ½æ˜¯å­¦ä¹ ä¸€ä¸ªæŠ•å½±çŸ©é˜µï¼Œä½¿æ ·æœ¬åœ¨æ–°çš„åæ ‡ç³»ä¸Šçš„è¡¨ç¤ºå…·æœ‰ç›¸åº”çš„ç‰¹æ€§ï¼Œæ ·æœ¬åœ¨æ–°åæ ‡ç³»çš„åæ ‡ç›¸å½“äºæ–°çš„ç‰¹å¾ï¼Œä¿ç•™ä¸‹çš„æ–°ç‰¹å¾åº”å½“æ˜¯å¯¹ç»“æœæœ‰è¾ƒå¤§å½±å“çš„ç‰¹å¾ã€‚

### PCAï¼ˆä¸»æˆåˆ†åˆ†æï¼‰

æœ€å¤§æ–¹å·®ç†è®ºï¼šä¿¡å·å…·æœ‰è¾ƒå¤§çš„æ–¹å·®ï¼Œå™ªå£°å…·æœ‰è¾ƒå°çš„æ–¹å·®
PCAçš„ç›®æ ‡ï¼šæ–°åæ ‡ç³»ä¸Šæ•°æ®çš„æ–¹å·®è¶Šå¤§è¶Šå¥½
PCAæ˜¯æ— ç›‘ç£çš„å­¦ä¹ æ–¹æ³•
PCAå®ç°èµ·æ¥å¹¶ä¸å¤æ‚ï¼ˆè¿‡å‡ å¤©å†™ä¸€ç¯‡ä½¿ç”¨NumPyå®ç°çš„PCAï¼‰ï¼Œä½†æ˜¯åœ¨sklearnå°±æ›´ä¸ºç®€å•äº†ï¼Œç›´æ¥é£Ÿç”¨skleran.decompositionå³å¯

```python
# -*- coding: utf-8 -*-
"""
Created on Wed Apr 24 21:54:33 2019

@author: zangz
"""
import numpy as np
#ä»sklearnä¸­å€’å…¥æ•°æ®é›†
from sklearn import datasets 
#å¯¼å…¥pcaçš„æ¨¡å—
import sklearn.decomposition as sk_decomposition
#å¯¼å…¥é¸¢å°¾èŠ±çš„æ•°æ®é›†
iris =datasets.load_iris()  
iris_X=iris.data  #æ•°æ®çš„ç‰¹å¾(4ä¸ªå±æ€§)
iris_Y=iris.target#æ•°æ®çš„æ ‡ç­¾(3ä¸ªåˆ†ç±»,0,1,2)
#åˆ›å»ºæ¨¡å‹
pca = sk_decomposition.PCA(n_components='mle',whiten=False,svd_solver='auto')
#è®­ç»ƒæ¨¡å‹
pca.fit(iris_X)

# ä½¿ç”¨ä¸Šé¢è¿™ä¸ªè½¬æ¢å™¨å»è½¬æ¢è®­ç»ƒæ•°æ®x,è°ƒç”¨transformæ–¹æ³•
reduced_X = pca.transform(iris_X) #reduced_Xä¸ºé™ç»´åçš„æ•°æ®
print('PCA:')
print ('é™ç»´åçš„å„ä¸»æˆåˆ†çš„æ–¹å·®å€¼å æ€»æ–¹å·®å€¼çš„æ¯”ä¾‹',pca.explained_variance_ratio_)
print ('é™ç»´åçš„å„ä¸»æˆåˆ†çš„æ–¹å·®å€¼',pca.explained_variance_)
print ('é™ç»´åçš„ç‰¹å¾æ•°',pca.n_components_)
```

å‚æ•°è¯´æ˜ï¼š
n_componentsï¼šæŒ‡å®šå¸Œæœ›PCAé™ç»´åçš„ç‰¹å¾ç»´åº¦æ•°ç›®(>1)ï¼Œ æŒ‡å®šä¸»æˆåˆ†çš„æ–¹å·®å’Œæ‰€å çš„æœ€å°æ¯”ä¾‹é˜ˆå€¼ï¼ˆ0-1ï¼‰ï¼Œ'mle'ç”¨MLEç®—æ³•æ ¹æ®ç‰¹å¾çš„æ–¹å·®åˆ†å¸ƒæƒ…å†µè‡ªå·±å»é€‰æ‹©ä¸€å®šæ•°é‡çš„ä¸»æˆåˆ†ç‰¹å¾æ¥é™ç»´
whitenï¼š åˆ¤æ–­æ˜¯å¦è¿›è¡Œç™½åŒ–ã€‚ç™½åŒ–ï¼šé™ç»´åçš„æ•°æ®çš„æ¯ä¸ªç‰¹å¾è¿›è¡Œå½’ä¸€åŒ–ï¼Œè®©æ–¹å·®éƒ½ä¸º1
svd_solverï¼šå¥‡å¼‚å€¼åˆ†è§£SVDçš„æ–¹æ³•{â€˜autoâ€™, â€˜fullâ€™, â€˜arpackâ€™, â€˜randomizedâ€™}

æ‰“å°ç»“æœ:
ä¸‹é¢æ‰“å°çš„å†…å®¹åªæ˜¯å¸®åŠ©å¤§å®¶ç†è§£pcaçš„å‚æ•°ï¼Œå°±ä¸æ‰“å°é™ç»´åçš„æ•°æ®äº†ï¼Œæ‰“å°å‡ºæ¥å¹¶æ²¡æœ‰ä»€ä¹ˆæ„ä¹‰ã€‚

```python
PCA:
é™ç»´åçš„å„ä¸»æˆåˆ†çš„æ–¹å·®å€¼å æ€»æ–¹å·®å€¼çš„æ¯”ä¾‹ [ 0.92461621  0.05301557  0.01718514]
é™ç»´åçš„å„ä¸»æˆåˆ†çš„æ–¹å·®å€¼ [ 4.22484077  0.24224357  0.07852391]
é™ç»´åçš„ç‰¹å¾æ•° 3

```

### LDAï¼ˆçº¿æ€§è¯„ä»·åˆ†æï¼‰

LDAåŸºäºè´¹èˆå°”å‡†åˆ™ï¼Œå³åŒä¸€ç±»æ ·æœ¬å°½å¯èƒ½èšåˆåœ¨ä¸€èµ·ï¼Œä¸åŒç±»æ ·æœ¬åº”è¯¥å°½é‡æ‰©æ•£ï¼›æˆ–è€…è¯´ï¼ŒåŒç±»å†…å…·æœ‰è¾ƒå¥½çš„èšåˆåº¦ï¼Œç±»åˆ«é—´å…·æœ‰è¾ƒå¥½çš„æ‰©æ•£åº¦ã€‚
æ—¢ç„¶æ¶‰åŠåˆ°äº†ç±»åˆ«ï¼Œé‚£ä¹ˆLDAè‚¯å®šæ˜¯ä¸€ä¸ªæœ‰ç›‘ç£ç®—æ³•ï¼Œå…¶å®LDAæ—¢å¯ä»¥åšç‰¹å¾æå–ä¹Ÿå¯ä»¥åšåˆ†ç±»ã€‚
LDAå…·ä½“çš„å®ç°æµç¨‹è¿™é‡Œå°±ä¸å†èµ˜è¿°äº†ï¼Œç›´æ¥çœ‹skleranå¦‚ä½•å®ç°LDAã€‚

```python
# -*- coding: utf-8 -*-
"""
Created on Wed Apr 24 22:13:29 2019

@author: zangz
"""
import numpy as np
#ä»sklearnä¸­å€’å…¥æ•°æ®é›†
from sklearn import datasets 
from sklearn.model_selection import train_test_split 

#å¯¼å…¥ä½¿ç”¨:LDAçš„æ¨¡å—
import sklearn.discriminant_analysis as sk_discriminant_analysis
#å¯¼å…¥é¸¢å°¾èŠ±çš„æ•°æ®é›†
iris =datasets.load_iris()  
iris_X=iris.data  #æ•°æ®çš„ç‰¹å¾(4ä¸ªå±æ€§)
iris_Y=iris.target#æ•°æ®çš„æ ‡ç­¾(3ä¸ªåˆ†ç±»,0,1,2)
#æ•°æ®çš„åˆ‡å‰²(7:3),æ•°æ®ä¼šè¢«æ‰“ä¹±
X_train,X_test,y_train,y_test=train_test_split(iris_X,iris_Y,test_size=0.3)

#å»ºç«‹LDAæ¨¡å‹
lda = sk_discriminant_analysis.LinearDiscriminantAnalysis(n_components=2)
#è®­ç»ƒæ¨¡å‹(ä½¿ç”¨è®­ç»ƒæ•°æ®)
lda.fit(X_train,y_train)


reduced_X = lda.transform(iris_X) #reduced_Xä¸ºé™ç»´åçš„æ•°æ®
print('LDA:')
print ('LDAçš„æ•°æ®ä¸­å¿ƒç‚¹:',lda.means_) #ä¸­å¿ƒç‚¹
print ('LDAåšåˆ†ç±»æ—¶çš„æ­£ç¡®ç‡:',lda.score(X_test, y_test)) #scoreæ˜¯æŒ‡åˆ†ç±»çš„æ­£ç¡®ç‡
print ('LDAé™ç»´åç‰¹å¾ç©ºé—´çš„ç±»ä¸­å¿ƒ:',lda.scalings_) #é™ç»´åç‰¹å¾ç©ºé—´çš„ç±»ä¸­å¿ƒ


```

å‚æ•°è¯´æ˜ï¼š
n_componentsï¼šæŒ‡å®šå¸Œæœ›PCAé™ç»´åçš„ç‰¹å¾ç»´åº¦æ•°ç›®(>1)
svd_solverï¼šå¥‡å¼‚å€¼åˆ†è§£SVDçš„æ–¹æ³•{â€˜autoâ€™, â€˜fullâ€™, â€˜arpackâ€™, â€˜randomizedâ€™}

æ‰“å°ç»“æœ:
ä¸‹é¢æ‰“å°çš„å†…å®¹åªæ˜¯å¸®åŠ©å¤§å®¶ç†è§£ldaçš„å‚æ•°ï¼Œå°±ä¸æ‰“å°é™ç»´åçš„æ•°æ®äº†ï¼Œæ‰“å°å‡ºæ¥å¹¶æ²¡æœ‰ä»€ä¹ˆæ„ä¹‰ã€‚

```python
LDA:
LDAçš„æ•°æ®ä¸­å¿ƒç‚¹: [[5.00294118 3.45588235 1.43823529 0.24411765]
 [5.96111111 2.78888889 4.35833333 1.36111111]
 [6.56857143 3.         5.55428571 2.03714286]]
LDAåšåˆ†ç±»æ—¶çš„æ­£ç¡®ç‡: 0.9777777777777777
LDAé™ç»´åç‰¹å¾ç©ºé—´çš„ç±»ä¸­å¿ƒ: [[-0.67612774  0.08223592]
 [-1.69411935  2.00705368]
 [ 2.27193737 -1.11662635]
 [ 2.95645633  3.1900014 ]]
```

## å¸¸ç”¨æ¨¡å‹
æœºå™¨å­¦ä¹ å¸¸ç”¨çš„ç®—æ³•ä¹Ÿå°±é‚£å‡ ä¸ªï¼Œsklearnä¸­å¯¹å…¶éƒ½åšäº†å®ç°ï¼Œæˆ‘ä»¬åªéœ€è¦è°ƒç”¨å³å¯ã€‚ä¸‹é¢æ¯ä¸€ä¸ªç®—æ³•çš„åŸç†æˆ‘å°±ä¸ç»†è®²äº†ï¼Œåªè®²æ€ä¹ˆç”¨.

é¦–å…ˆsklearnä¸­æ‰€æœ‰çš„æ¨¡å‹éƒ½æœ‰å››ä¸ªå›ºå®šä¸”å¸¸ç”¨çš„æ–¹æ³•ï¼Œå…¶å®åœ¨PCAä¸LDAä¸­æˆ‘ä»¬å·²ç»ç”¨åˆ°äº†è¿™äº›æ–¹æ³•ä¸­çš„fitæ–¹æ³•ã€‚

```python
# æ‹Ÿåˆæ¨¡å‹
model.fit(X_train, y_train)
# æ¨¡å‹é¢„æµ‹
model.predict(X_test)
# è·å¾—è¿™ä¸ªæ¨¡å‹çš„å‚æ•°
model.get_params()
# ä¸ºæ¨¡å‹è¿›è¡Œæ‰“åˆ†
model.score(data_X, data_y) # å›å½’é—®é¢˜ï¼šä»¥R2å‚æ•°ä¸ºæ ‡å‡† åˆ†ç±»é—®é¢˜ï¼šä»¥å‡†ç¡®ç‡ä¸ºæ ‡å‡†

```

### çº¿æ€§å›å½’

çº¿æ€§å›å½’æ˜¯åˆ©ç”¨æ•°ç†ç»Ÿè®¡ä¸­å›å½’åˆ†æï¼Œæ¥ç¡®å®šä¸¤ç§æˆ–ä¸¤ç§ä»¥ä¸Šå˜é‡é—´ç›¸äº’ä¾èµ–çš„å®šé‡å…³ç³»çš„ä¸€ç§ç»Ÿè®¡åˆ†ææ–¹æ³•ï¼Œè¿ç”¨ååˆ†å¹¿æ³›ã€‚å…¶è¡¨è¾¾å½¢å¼ä¸º`y = w'x+e`ï¼Œeä¸ºè¯¯å·®æœä»å‡å€¼ä¸º0çš„æ­£æ€åˆ†å¸ƒã€‚
å›å½’åˆ†æä¸­ï¼ŒåªåŒ…æ‹¬ä¸€ä¸ªè‡ªå˜é‡å’Œä¸€ä¸ªå› å˜é‡ï¼Œä¸”äºŒè€…çš„å…³ç³»å¯ç”¨ä¸€æ¡ç›´çº¿è¿‘ä¼¼è¡¨ç¤ºï¼Œè¿™ç§å›å½’åˆ†æç§°ä¸ºä¸€å…ƒçº¿æ€§å›å½’åˆ†æã€‚å¦‚æœå›å½’åˆ†æä¸­åŒ…æ‹¬ä¸¤ä¸ªæˆ–ä¸¤ä¸ªä»¥ä¸Šçš„è‡ªå˜é‡ï¼Œä¸”å› å˜é‡å’Œè‡ªå˜é‡ä¹‹é—´æ˜¯çº¿æ€§å…³ç³»ï¼Œåˆ™ç§°ä¸ºå¤šå…ƒçº¿æ€§å›å½’åˆ†æã€‚
å…¶å®ï¼Œè¯´ç™½äº†ï¼Œå°±æ˜¯ç”¨ä¸€æ¡ç›´çº¿å»æ‹Ÿåˆä¸€å¤§å †æ•°æ®ï¼Œæœ€åæŠŠç³»æ•°wå’Œæˆªè·bç®—å‡ºæ¥ï¼Œç›´çº¿ä¹Ÿå°±ç®—å‡ºæ¥äº†ï¼Œ å°±å¯ä»¥æ‹¿å»åšé¢„æµ‹äº†ã€‚
sklearnä¸­çº¿æ€§å›å½’ä½¿ç”¨æœ€å°äºŒä¹˜æ³•å®ç°ï¼Œä½¿ç”¨èµ·æ¥éå¸¸ç®€å•ã€‚
çº¿æ€§å›å½’æ˜¯å›å½’é—®é¢˜ï¼Œscoreä½¿ç”¨R2ç³»æ•°åšä¸ºè¯„ä»·æ ‡å‡†ã€‚

```python
# -*- coding: utf-8 -*-
"""
Created on Thu Apr 25 09:47:00 2019

@author: zangz
"""
import numpy as np
#ä»sklearnä¸­å€’å…¥æ•°æ®é›†
from sklearn import datasets 
#åˆ‡åˆ†è®­ç»ƒé›†æµ‹è¯•é›†çš„æ¨¡å—
#from sklearn.cross_validation import train_test_split 
from sklearn.model_selection import train_test_split 
import sklearn.linear_model as sk_linear

#ä½¿ç”¨çš„é¸¢å°¾èŠ±çš„æ•°æ®é›†
iris =datasets.load_iris()  
iris_X=iris.data  #æ•°æ®çš„ç‰¹å¾(4ä¸ªå±æ€§)
iris_Y=iris.target#æ•°æ®çš„æ ‡ç­¾(3ä¸ªåˆ†ç±»,0,1,2)

#æ•°æ®çš„åˆ‡å‰²(7:3),æ•°æ®ä¼šè¢«æ‰“ä¹±
X_train,X_test,y_train,y_test=train_test_split(iris_X,iris_Y,test_size=0.3)
#åˆ›å»ºæ¨¡å‹
model = sk_linear.LinearRegression(fit_intercept=True,normalize=False,copy_X=True,n_jobs=1)
#è®­ç»ƒæ¨¡å‹
model.fit(X_train,y_train)
#è¯„ä»·æ¨¡å‹
acc=model.score(X_test,y_test) #è¿”å›é¢„æµ‹çš„ç¡®å®šç³»æ•°R2
print('çº¿æ€§å›å½’:')
print('æˆªè·:',model.intercept_) #è¾“å‡ºæˆªè·
print('ç³»æ•°:',model.coef_) #è¾“å‡ºç³»æ•°
print('çº¿æ€§å›å½’æ¨¡å‹è¯„ä»·:',acc)

```

å‚æ•°è¯´æ˜ï¼š
fit_interceptï¼šæ˜¯å¦è®¡ç®—æˆªè·ã€‚False-æ¨¡å‹æ²¡æœ‰æˆªè·
normalizeï¼š å½“fit_interceptè®¾ç½®ä¸ºFalseæ—¶ï¼Œè¯¥å‚æ•°å°†è¢«å¿½ç•¥ã€‚ å¦‚æœä¸ºçœŸï¼Œåˆ™å›å½’å‰çš„å›å½’ç³»æ•°Xå°†é€šè¿‡å‡å»å¹³å‡å€¼å¹¶é™¤ä»¥l2-èŒƒæ•°è€Œå½’ä¸€åŒ–ã€‚
copy_Xï¼šæ˜¯å¦å¯¹Xæ•°ç»„è¿›è¡Œå¤åˆ¶,é»˜è®¤ä¸ºTrue
n_jobsï¼šæŒ‡å®šçº¿ç¨‹æ•°

æ‰“å°ç»“æœï¼š

```python
çº¿æ€§å›å½’:
æˆªè·: 0.360007142807655
ç³»æ•°: [-0.23016056  0.04521955  0.33913525  0.47029646]
çº¿æ€§å›å½’æ¨¡å‹è¯„ä»·: 0.9252305022245975
```

### é€»è¾‘å›å½’

logisticå›å½’æ˜¯ä¸€ç§å¹¿ä¹‰çº¿æ€§å›å½’ï¼ˆgeneralized linear modelï¼‰ï¼Œå› æ­¤ä¸å¤šé‡çº¿æ€§å›å½’åˆ†ææœ‰å¾ˆå¤šç›¸åŒä¹‹å¤„ã€‚å®ƒä»¬çš„æ¨¡å‹å½¢å¼åŸºæœ¬ä¸Šç›¸åŒï¼Œéƒ½å…·æœ‰ `wâ€˜x+b`ï¼Œå…¶ä¸­wå’Œbæ˜¯å¾…æ±‚å‚æ•°ï¼Œå…¶åŒºåˆ«åœ¨äºä»–ä»¬çš„**`å› å˜é‡`**ä¸åŒï¼Œå¤šé‡çº¿æ€§å›å½’ç›´æ¥å°†wâ€˜x+bä½œä¸ºå› å˜é‡ï¼Œå³y =wâ€˜x+bï¼Œè€Œlogisticå›å½’åˆ™é€šè¿‡å‡½æ•°Lå°†wâ€˜x+bå¯¹åº”ä¸€ä¸ªéšçŠ¶æ€`p`ï¼Œp =L(wâ€˜x+b),ç„¶åæ ¹æ®p ä¸1-pçš„å¤§å°å†³å®šå› å˜é‡çš„å€¼ã€‚å¦‚æœLæ˜¯logisticå‡½æ•°ï¼Œå°±æ˜¯logisticå›å½’ï¼Œå¦‚æœLæ˜¯å¤šé¡¹å¼å‡½æ•°å°±æ˜¯å¤šé¡¹å¼å›å½’ã€‚
è¯´äººè¯ï¼š**çº¿æ€§å›å½’æ˜¯å›å½’ï¼Œé€»è¾‘å›å½’æ˜¯åˆ†ç±»ã€‚é€»è¾‘å›å½’é€šè¿‡logisticå‡½æ•°ç®—æ¦‚ç‡ï¼Œç„¶åç®—å‡ºæ¥ä¸€ä¸ªæ ·æœ¬å±äºä¸€ä¸ªç±»åˆ«çš„æ¦‚ç‡ï¼Œæ¦‚ç‡è¶Šå¤§è¶Šå¯èƒ½æ˜¯è¿™ä¸ªç±»çš„æ ·æœ¬**ã€‚
sklearnå¯¹äºé€»è¾‘å›å½’çš„å®ç°ä¹Ÿéå¸¸ç®€å•ï¼Œç›´æ¥ä¸Šä»£ç äº†ã€‚
é€»è¾‘å›å½’æ˜¯åˆ†ç±»é—®é¢˜ï¼Œscoreä½¿ç”¨å‡†ç¡®ç‡åšä¸ºè¯„ä»·æ ‡å‡†ã€‚

```python
# -*- coding: utf-8 -*-
"""
Created on Thu Apr 25 09:53:41 2019

@author: zangz
"""

# -*- coding: utf-8 -*-
"""
Created on Thu Apr 25 09:47:00 2019

@author: zangz
"""
import numpy as np
#ä»sklearnä¸­å€’å…¥æ•°æ®é›†
from sklearn import datasets 
#åˆ‡åˆ†è®­ç»ƒé›†æµ‹è¯•é›†çš„æ¨¡å—
#from sklearn.cross_validation import train_test_split 
from sklearn.model_selection import train_test_split 
#å¯¼å…¥é€»è¾‘å›å½’çš„åŒ…
import sklearn.linear_model as sk_linear

#ä½¿ç”¨çš„é¸¢å°¾èŠ±çš„æ•°æ®é›†
iris =datasets.load_iris()  
iris_X=iris.data  #æ•°æ®çš„ç‰¹å¾(4ä¸ªå±æ€§)
iris_Y=iris.target#æ•°æ®çš„æ ‡ç­¾(3ä¸ªåˆ†ç±»,0,1,2)

#æ•°æ®çš„åˆ‡å‰²(7:3),æ•°æ®ä¼šè¢«æ‰“ä¹±
X_train,X_test,y_train,y_test=train_test_split(iris_X,iris_Y,test_size=0.3)
#åˆ›å»ºæ¨¡å‹
model = sk_linear.LogisticRegression(penalty='l2',dual=False,C=1.0,n_jobs=1,random_state=20,fit_intercept=True,solver='lbfgs')

#è®­ç»ƒæ¨¡å‹
model.fit(X_train,y_train)
#è¯„ä»·æ¨¡å‹
acc=model.score(X_test,y_test) #è¿”å›é¢„æµ‹çš„ç¡®å®šç³»æ•°R2
print('é€»è¾‘å›å½’æ¨¡å‹è¯„ä»·:',acc)

```

å‚æ•°è¯´æ˜ï¼š
penaltyï¼šä½¿ç”¨æŒ‡å®šæ­£åˆ™åŒ–é¡¹ï¼ˆé»˜è®¤ï¼šl2ï¼‰
dual: n_samples > n_featureså–Falseï¼ˆé»˜è®¤ï¼‰
Cï¼šæ­£åˆ™åŒ–å¼ºåº¦çš„åï¼Œå€¼è¶Šå°æ­£åˆ™åŒ–å¼ºåº¦è¶Šå¤§
n_jobs: æŒ‡å®šçº¿ç¨‹æ•°
random_stateï¼šéšæœºæ•°ç”Ÿæˆå™¨
fit_intercept: æ˜¯å¦éœ€è¦å¸¸é‡

æ‰“å°ç»“æœï¼š

```
é€»è¾‘å›å½’æ¨¡å‹è¯„ä»·: 0.8 

```

### æœ´ç´ è´å¶æ–¯

è´å¶æ–¯åˆ†ç±»æ˜¯ä¸€ç±»åˆ†ç±»ç®—æ³•çš„æ€»ç§°ï¼Œè¿™ç±»ç®—æ³•å‡ä»¥è´å¶æ–¯å®šç†ä¸ºåŸºç¡€ï¼Œæ•…ç»Ÿç§°ä¸ºè´å¶æ–¯åˆ†ç±»ã€‚
è€Œæœ´ç´ æœ´ç´ è´å¶æ–¯åˆ†ç±»æ˜¯è´å¶æ–¯åˆ†ç±»ä¸­æœ€ç®€å•ï¼Œä¹Ÿæ˜¯å¸¸è§çš„ä¸€ç§åˆ†ç±»æ–¹æ³•
é¦–å…ˆæ ¹æ®æ ·æœ¬ä¸­å¿ƒå®šç†ï¼Œæ¦‚ç‡ç­‰äºé¢‘ç‡ï¼Œæ‰€ä»¥ä¸‹æ–‡çš„Pæ˜¯å¯ä»¥ç»Ÿè®¡å‡ºæ¥çš„
æœ´ç´ è´å¶æ–¯çš„æ ¸å¿ƒä¾¿æ˜¯è´å¶æ–¯å…¬å¼ï¼šP(B|A)=P(A|B)P(B) / P(A) å³åœ¨Aæ¡ä»¶ä¸‹ï¼ŒBå‘ç”Ÿçš„æ¦‚ç‡
æ¢ä¸ªè§’åº¦ï¼šP(ç±»åˆ«|ç‰¹å¾)=P(ç‰¹å¾|ç±»åˆ«)P(ç±»åˆ«)/P(ç‰¹å¾)
è€Œæˆ‘ä»¬æœ€åè¦æ±‚è§£çš„å°±æ˜¯P(ç±»åˆ«|ç‰¹å¾)
ä¸¾ä¸€ä¸ªç”Ÿæ´»ä¸­çš„ä¾‹å­ï¼š

![è´å¶æ–¯](http://upload-images.jianshu.io/upload_images/14555448-5a4cad2d68e0be1b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

æœ€åä¸€ä¸ªå…¬å¼ä¸­çš„æ‰€æœ‰æ¦‚ç‡éƒ½æ˜¯å¯ä»¥ç»Ÿè®¡å‡ºæ¥çš„ï¼Œæ‰€ä»¥P(B|A)å¯ä»¥è®¡ç®—ï¼
é‚£ä¹ˆï¼æˆ‘æ„Ÿè§‰æˆ‘éƒ½å†™åé¢˜äº†ï¼Œè¿™æ˜æ˜æ˜¯æœºå™¨å­¦ä¹ ç®—æ³•æ¦‚è¿°å˜›
é‚£ä¹ˆsklearnä¸­æ€ä¹ˆå®ç°å‘¢ï¼Ÿ

```python
# -*- coding: utf-8 -*-
"""
Created on Thu Apr 25 10:44:43 2019

@author: zangz
"""
import numpy as np
#ä»sklearnä¸­å€’å…¥æ•°æ®é›†
from sklearn import datasets 
#åˆ‡åˆ†è®­ç»ƒé›†æµ‹è¯•é›†çš„æ¨¡å—
#from sklearn.cross_validation import train_test_split 
from sklearn.model_selection import train_test_split 
#å¯¼å…¥è´å¶æ–¯çš„åŒ…
import sklearn.naive_bayes as sk_bayes

#ä½¿ç”¨çš„é¸¢å°¾èŠ±çš„æ•°æ®é›†
iris =datasets.load_iris()  
iris_X=iris.data  #æ•°æ®çš„ç‰¹å¾(4ä¸ªå±æ€§)
iris_Y=iris.target#æ•°æ®çš„æ ‡ç­¾(3ä¸ªåˆ†ç±»,0,1,2)

#æ•°æ®çš„åˆ‡å‰²(7:3),æ•°æ®ä¼šè¢«æ‰“ä¹±
X_train,X_test,y_train,y_test=train_test_split(iris_X,iris_Y,test_size=0.3)

model = sk_bayes.MultinomialNB(alpha=1.0,fit_prior=True,class_prior=None) #å¤šé¡¹å¼åˆ†å¸ƒçš„æœ´ç´ è´å¶æ–¯
model = sk_bayes.BernoulliNB(alpha=1.0,binarize=0.0,fit_prior=True,class_prior=None) #ä¼¯åŠªåˆ©åˆ†å¸ƒçš„æœ´ç´ è´å¶æ–¯
model = sk_bayes.GaussianNB()#é«˜æ–¯åˆ†å¸ƒçš„æœ´ç´ è´å¶æ–¯
model.fit(X_train,y_train)
acc=model.score(X_test,y_test) #æ ¹æ®ç»™å®šæ•°æ®ä¸æ ‡ç­¾è¿”å›æ­£ç¡®ç‡çš„å‡å€¼
print('æœ´ç´ è´å¶æ–¯(é«˜æ–¯åˆ†å¸ƒ)æ¨¡å‹è¯„ä»·:',acc)

```

å‚æ•°è¯´æ˜ï¼š
alphaï¼šå¹³æ»‘å‚æ•°
fit_priorï¼šæ˜¯å¦è¦å­¦ä¹ ç±»çš„å…ˆéªŒæ¦‚ç‡ï¼›false-ä½¿ç”¨ç»Ÿä¸€çš„å…ˆéªŒæ¦‚ç‡
class_prior: æ˜¯å¦æŒ‡å®šç±»çš„å…ˆéªŒæ¦‚ç‡ï¼›è‹¥æŒ‡å®šåˆ™ä¸èƒ½æ ¹æ®å‚æ•°è°ƒæ•´
binarize: äºŒå€¼åŒ–çš„é˜ˆå€¼ï¼Œè‹¥ä¸ºNoneï¼Œåˆ™å‡è®¾è¾“å…¥ç”±äºŒè¿›åˆ¶å‘é‡ç»„æˆ

æœ´ç´ è´å¶æ–¯å¸¸ç”¨çš„ä¸‰ä¸ªæ¨¡å‹æœ‰ï¼š

é«˜æ–¯æ¨¡å‹ï¼šå¤„ç†ç‰¹å¾æ˜¯è¿ç»­å‹å˜é‡çš„æƒ…å†µ
å¤šé¡¹å¼æ¨¡å‹ï¼šæœ€å¸¸è§ï¼Œè¦æ±‚ç‰¹å¾æ˜¯ç¦»æ•£æ•°æ®
ä¼¯åŠªåˆ©æ¨¡å‹ï¼šè¦æ±‚ç‰¹å¾æ˜¯ç¦»æ•£çš„ï¼Œä¸”ä¸ºå¸ƒå°”ç±»å‹ï¼Œå³trueå’Œfalseï¼Œæˆ–è€…1å’Œ0

æ‰“å°ç»“æœï¼š

```python
æœ´ç´ è´å¶æ–¯(é«˜æ–¯åˆ†å¸ƒ)æ¨¡å‹è¯„ä»·: 0.9777777777777777

```

### å†³ç­–æ ‘

å†³ç­–æ ‘æ˜¯è§£å†³åˆ†ç±»é—®é¢˜
å†³ç­–æ ‘â€”â€”ID3ç®—æ³•å®ç°
è¿™é‡Œæˆ‘ä»¬ç›´æ¥ä¸Šä»£ç 

```python

# -*- coding: utf-8 -*-
"""
Created on Thu Apr 25 10:44:43 2019

@author: zangz
"""
import numpy as np
#ä»sklearnä¸­å€’å…¥æ•°æ®é›†
from sklearn import datasets 
#åˆ‡åˆ†è®­ç»ƒé›†æµ‹è¯•é›†çš„æ¨¡å—
#from sklearn.cross_validation import train_test_split 
from sklearn.model_selection import train_test_split 
#å¯¼å…¥å†³ç­–æ ‘çš„åŒ…
import sklearn.tree as sk_tree

#ä½¿ç”¨çš„é¸¢å°¾èŠ±çš„æ•°æ®é›†
iris =datasets.load_iris()  
iris_X=iris.data  #æ•°æ®çš„ç‰¹å¾(4ä¸ªå±æ€§)
iris_Y=iris.target#æ•°æ®çš„æ ‡ç­¾(3ä¸ªåˆ†ç±»,0,1,2)

#æ•°æ®çš„åˆ‡å‰²(7:3),æ•°æ®ä¼šè¢«æ‰“ä¹±
X_train,X_test,y_train,y_test=train_test_split(iris_X,iris_Y,test_size=0.3)
#åˆ›å»ºID3ç®—æ³•çš„æ¨¡å‹
model = sk_tree.DecisionTreeClassifier(criterion='entropy',max_depth=None,min_samples_split=2,min_samples_leaf=1,max_features=None,max_leaf_nodes=None,min_impurity_decrease=0)
#è®­ç»ƒæ¨¡å‹
model.fit(X_train,y_train)
#æ¨¡å‹çš„è¯„ä»·
acc=model.score(X_test,y_test) #æ ¹æ®ç»™å®šæ•°æ®ä¸æ ‡ç­¾è¿”å›æ­£ç¡®ç‡çš„å‡å€¼
print('å†³ç­–æ ‘æ¨¡å‹è¯„ä»·:',acc)

```

å‚æ•°è¯´æ˜ï¼š
criterion ï¼šç‰¹å¾é€‰æ‹©å‡†åˆ™gini/entropy
max_depthï¼šæ ‘çš„æœ€å¤§æ·±åº¦ï¼ŒNone-å°½é‡ä¸‹åˆ†
min_samples_splitï¼šåˆ†è£‚å†…éƒ¨èŠ‚ç‚¹ï¼Œæ‰€éœ€è¦çš„æœ€å°æ ·æœ¬æ ‘
min_samples_leafï¼šå¶å­èŠ‚ç‚¹æ‰€éœ€è¦çš„æœ€å°æ ·æœ¬æ•°
max_features: å¯»æ‰¾æœ€ä¼˜åˆ†å‰²ç‚¹æ—¶çš„æœ€å¤§ç‰¹å¾æ•°
max_leaf_nodesï¼šä¼˜å…ˆå¢é•¿åˆ°æœ€å¤§å¶å­èŠ‚ç‚¹æ•°
min_impurity_decreaseï¼šå¦‚æœè¿™ç§åˆ†ç¦»å¯¼è‡´æ‚è´¨çš„å‡å°‘å¤§äºæˆ–ç­‰äºè¿™ä¸ªå€¼ï¼Œåˆ™èŠ‚ç‚¹å°†è¢«æ‹†åˆ†ã€‚

æ‰“å°ç»“æœï¼š

```python
å†³ç­–æ ‘æ¨¡å‹è¯„ä»·: 0.942857142857

```

### SVM(æ”¯æŒå‘é‡æœºï¼‰

æ”¯æŒå‘é‡æœºæ˜¯è§£å†³åˆ†ç±»é—®é¢˜
ç›®çš„ï¼šæ±‚è§£æœ€å¤§åŒ–é—´éš”
æ”¯æŒå‘é‡æœºå°†å‘é‡æ˜ å°„åˆ°ä¸€ä¸ªæ›´é«˜ç»´çš„ç©ºé—´é‡Œï¼Œåœ¨è¿™ä¸ªç©ºé—´é‡Œå»ºç«‹æœ‰ä¸€ä¸ªæœ€å¤§é—´éš”è¶…å¹³é¢ã€‚åœ¨åˆ†å¼€æ•°æ®çš„è¶…å¹³é¢çš„ä¸¤è¾¹å»ºæœ‰ä¸¤ä¸ªäº’ç›¸å¹³è¡Œçš„è¶…å¹³é¢ã€‚å»ºç«‹æ–¹å‘åˆé€‚çš„åˆ†éš”è¶…å¹³é¢ä½¿ä¸¤ä¸ªä¸ä¹‹å¹³è¡Œçš„è¶…å¹³é¢é—´çš„è·ç¦»æœ€å¤§åŒ–ã€‚å…¶å‡å®šä¸ºï¼Œå¹³è¡Œè¶…å¹³é¢é—´çš„è·ç¦»æˆ–å·®è·è¶Šå¤§ï¼Œåˆ†ç±»å™¨çš„æ€»è¯¯å·®è¶Šå°ã€‚
SVMçš„å…³é”®åœ¨äºæ ¸å‡½æ•°
ä¸€å¥è¯è®²æ‡‚æ ¸å‡½æ•°ï¼šä½ç»´æ— æ³•çº¿æ€§åˆ’åˆ†çš„é—®é¢˜æ”¾åˆ°é«˜ç»´å°±å¯ä»¥çº¿æ€§åˆ’åˆ†ï¼Œä¸€èˆ¬ç”¨é«˜æ–¯ï¼Œå› ä¸ºæ•ˆæœç»å¯¹ä¸ä¼šå˜å·®ï¼
SVMç®—æ³•æ€è·¯å¾ˆæ¸…æ™°ï¼Œä½†æ˜¯å®ç°èµ·æ¥å¾ˆå¤æ‚

```python
# -*- coding: utf-8 -*-
"""
Created on Thu Apr 25 10:44:43 2019

@author: zangz
"""
import numpy as np
#ä»sklearnä¸­å€’å…¥æ•°æ®é›†
from sklearn import datasets 
#åˆ‡åˆ†è®­ç»ƒé›†æµ‹è¯•é›†çš„æ¨¡å—
#from sklearn.cross_validation import train_test_split 
from sklearn.model_selection import train_test_split 
#å¯¼å…¥SVMçš„åŒ…
import sklearn.svm as sk_svm

#ä½¿ç”¨çš„é¸¢å°¾èŠ±çš„æ•°æ®é›†
iris =datasets.load_iris()  
iris_X=iris.data  #æ•°æ®çš„ç‰¹å¾(4ä¸ªå±æ€§)
iris_Y=iris.target#æ•°æ®çš„æ ‡ç­¾(3ä¸ªåˆ†ç±»,0,1,2)

#æ•°æ®çš„åˆ‡å‰²(7:3),æ•°æ®ä¼šè¢«æ‰“ä¹±
X_train,X_test,y_train,y_test=train_test_split(iris_X,iris_Y,test_size=0.3)
#åˆ›å»ºSVMç®—æ³•çš„æ¨¡å‹
model = sk_svm.SVC(C=1.0,kernel='rbf',gamma='auto')
model.fit(X_train,y_train)
acc=model.score(X_test,y_test) #æ ¹æ®ç»™å®šæ•°æ®ä¸æ ‡ç­¾è¿”å›æ­£ç¡®ç‡çš„å‡å€¼
print('SVMæ¨¡å‹è¯„ä»·:',acc)
```

å‚æ•°è¯´æ˜ï¼š
Cï¼šè¯¯å·®é¡¹çš„æƒ©ç½šå‚æ•°C
kernelï¼šæ ¸å‡½æ•°é€‰æ‹© é»˜è®¤ï¼šrbf(é«˜æ–¯æ ¸å‡½æ•°)ï¼Œå¯é€‰ï¼šâ€˜linearâ€™, â€˜polyâ€™, â€˜rbfâ€™, â€˜sigmoidâ€™, â€˜precomputedâ€™
gamma: æ ¸ç›¸å…³ç³»æ•°ã€‚æµ®ç‚¹æ•°ï¼ŒIf gamma is â€˜autoâ€™ then 1/n_features will be used instead.ç‚¹å°†è¢«æ‹†åˆ†ã€‚

æ‰“å°ç»“æœï¼š

```
SVMæ¨¡å‹è¯„ä»·: 0.961904761905

```

### ç¥ç»ç½‘ç»œ

è¿˜åœ¨æ„Ÿæ…¨å› ä¸ºä¸ä¼štensorflowè€Œæ— æ³•ä½¿ç”¨ç¥ç»ç½‘ç»œï¼Ÿè¿˜åœ¨ç¾¡æ…•ç¥ç»ç½‘ç»œçš„æƒŠäººæ•ˆæœ?ä¸éœ€è¦tfï¼Œä¸éœ€è¦caffeï¼Œä¸éœ€è¦pytorchï¼åªè¦ä¸€å¥è¯ï¼Œä¾¿å¯ä»¥å®ç°å¤šå±‚ç¥ç»ç½‘ç»œï¼ï¼ï¼
åœ¨è¿™é‡Œè¿˜æ˜¯ç®€å•è¯´ä¸€ä¸‹M-Pç¥ç»å…ƒçš„åŸç†ï¼š

![ç¥ç»å…ƒ](http://upload-images.jianshu.io/upload_images/14555448-ab4b86ddb6cd303b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

ğ’™ğ’Š æ¥è‡ªç¬¬ğ‘–ä¸ªç¥ç»å…ƒçš„è¾“å…¥
ğ’˜ğ’Š ç¬¬ğ‘–ä¸ªç¥ç»å…ƒçš„è¿æ¥æƒé‡
ğœ½ é˜ˆå€¼(threshold)æˆ–ç§°ä¸ºåç½®ï¼ˆbiasï¼‰
ğ‘“ ä¸ºæ¿€æ´»å‡½æ•°ï¼Œå¸¸ç”¨ï¼šsigmoidï¼Œreluï¼Œtanhç­‰ç­‰
å¯¹äºä¸€ä¸ªç¥ç»å…ƒæ¥è¯´ï¼Œæœ‰iä¸ªè¾“å…¥ï¼Œæ¯ä¸€ä¸ªè¾“å…¥éƒ½å¯¹åº”ä¸€ä¸ªæƒé‡ï¼ˆwï¼‰ï¼Œç¥ç»å…ƒå…·æœ‰ä¸€ä¸ªåç½®ï¼ˆé˜ˆå€¼ï¼‰ï¼Œå°†æ‰€æœ‰çš„i*wæ±‚å’Œåå‡å»é˜ˆå€¼å¾—åˆ°ä¸€ä¸ªå€¼ï¼Œè¿™ä¸ªå€¼å°±æ˜¯æ¿€æ´»å‡½æ•°çš„å‚æ•°ï¼Œæ¿€æ´»å‡½æ•°å°†æ ¹æ®è¿™ä¸ªå‚æ•°æ¥åˆ¤å®šè¿™ä¸ªç¥ç»å…ƒæ˜¯å¦è¢«æ¿€æ´»ã€‚
æœ¬è´¨ä¸Š, M-Pç¥ç»å…ƒ=çº¿æ€§äºŒåˆ†ç±»å™¨
é‚£ä¹ˆä»€ä¹ˆæ˜¯å¤šå±‚ç¥ç»ç½‘ç»œï¼Ÿ
çº¿æ€§ä¸å¯åˆ†ï¼šä¸€ä¸ªè¶…å¹³é¢æ²¡æ³•è§£å†³é—®é¢˜ï¼Œå°±ç”¨ä¸¤ä¸ªè¶…å¹³é¢æ¥è§£å†³ï¼Œä»€ä¹ˆï¼Ÿè¿˜ä¸è¡Œï¼é‚£å°±å†å¢åŠ è¶…å¹³é¢ç›´åˆ°è§£å†³é—®é¢˜ä¸ºæ­¢ã€‚ â€”â€”å¤šå±‚ç¥ç»ç½‘ç»œ
æ²¡é”™ï¼Œå¤šå±‚ç¥ç»å…ƒå°±æ˜¯ç”¨æ¥è§£å†³çº¿æ€§ä¸å¯åˆ†é—®é¢˜çš„ã€‚
é‚£ä¹ˆï¼Œsklearnä¸­å¦‚ä½•å®ç°å‘¢ï¼Ÿ

```python

# -*- coding: utf-8 -*-
"""
Created on Thu Apr 25 10:44:43 2019

@author: zangz
"""
import numpy as np
#ä»sklearnä¸­å€’å…¥æ•°æ®é›†
from sklearn import datasets 
#åˆ‡åˆ†è®­ç»ƒé›†æµ‹è¯•é›†çš„æ¨¡å—
#from sklearn.cross_validation import train_test_split 
from sklearn.model_selection import train_test_split 
#å¯¼å…¥ç¥ç»ç½‘ç»œçš„åŒ…
import sklearn.neural_network as sk_nn

#ä½¿ç”¨çš„é¸¢å°¾èŠ±çš„æ•°æ®é›†
iris =datasets.load_iris()  
iris_X=iris.data  #æ•°æ®çš„ç‰¹å¾(4ä¸ªå±æ€§)
iris_Y=iris.target#æ•°æ®çš„æ ‡ç­¾(3ä¸ªåˆ†ç±»,0,1,2)

#æ•°æ®çš„åˆ‡å‰²(7:3),æ•°æ®ä¼šè¢«æ‰“ä¹±
X_train,X_test,y_train,y_test=train_test_split(iris_X,iris_Y,test_size=0.3)
#åˆ›å»ºç¥ç»ç½‘ç»œç®—æ³•çš„æ¨¡å‹
model = sk_nn.MLPClassifier(activation='tanh',solver='adam',alpha=0.0001,learning_rate='adaptive',learning_rate_init=0.001,max_iter=200)
model.fit(X_train,y_train)
acc=model.score(X_test,y_test) #æ ¹æ®ç»™å®šæ•°æ®ä¸æ ‡ç­¾è¿”å›æ­£ç¡®ç‡çš„å‡å€¼
print('ç¥ç»ç½‘ç»œæ¨¡å‹è¯„ä»·:',acc)

```

å‚æ•°è¯´æ˜ï¼š
hidden_layer_sizes: å…ƒç¥–
activationï¼šæ¿€æ´»å‡½æ•° {â€˜identityâ€™, â€˜logisticâ€™, â€˜tanhâ€™, â€˜reluâ€™}, é»˜è®¤ â€˜reluâ€™
solver ï¼šä¼˜åŒ–ç®—æ³•{â€˜lbfgsâ€™, â€˜sgdâ€™, â€˜Adamâ€™}
alphaï¼šL2æƒ©ç½š(æ­£åˆ™åŒ–é¡¹)å‚æ•°
learning_rateï¼šå­¦ä¹ ç‡ {â€˜constantâ€™, â€˜invscalingâ€™, â€˜adaptiveâ€™}
learning_rate_initï¼šåˆå§‹å­¦ä¹ ç‡ï¼Œé»˜è®¤0.001
max_iterï¼šæœ€å¤§è¿­ä»£æ¬¡æ•° é»˜è®¤200

ç‰¹åˆ«ï¼š
å­¦ä¹ ç‡ä¸­å‚æ•°ï¼š
constant: æœ‰â€˜learning_rate_initâ€™ç»™å®šçš„æ’å®šå­¦ä¹ ç‡
incscalingï¼šéšç€æ—¶é—´tä½¿ç”¨â€™power_tâ€™çš„é€†æ ‡åº¦æŒ‡æ•°ä¸æ–­é™ä½å­¦ä¹ ç‡
adaptiveï¼šåªè¦è®­ç»ƒæŸè€—åœ¨ä¸‹é™ï¼Œå°±ä¿æŒå­¦ä¹ ç‡ä¸ºâ€™learning_rate_initâ€™ä¸å˜
ä¼˜åŒ–ç®—æ³•å‚æ•°ï¼š
lbfgsï¼šquasi-Newtonæ–¹æ³•çš„ä¼˜åŒ–å™¨
sgdï¼šéšæœºæ¢¯åº¦ä¸‹é™
adamï¼š Kingma, Diederik, and Jimmy Baæå‡ºçš„æœºé‡éšæœºæ¢¯åº¦çš„ä¼˜åŒ–å™¨

æ‰“å°ç»“æœï¼šï¼ˆç¥ç»ç½‘ç»œçš„ç¡®ç‰›é€¼ï¼‰

```
ç¥ç»ç½‘ç»œæ¨¡å‹è¯„ä»·: 0.980952380952

```

### KNNï¼ˆK-è¿‘é‚»ç®—æ³•ï¼‰

KNNå¯ä»¥è¯´æ˜¯éå¸¸å¥½ç”¨ï¼Œä¹Ÿéå¸¸å¸¸ç”¨çš„åˆ†ç±»ç®—æ³•äº†ï¼Œä¹Ÿæ˜¯æœ€ç®€å•æ˜“æ‡‚çš„æœºå™¨å­¦ä¹ ç®—æ³•ï¼Œæ²¡æœ‰ä¹‹ä¸€ã€‚ç”±äºç®—æ³•å…ˆå¤©ä¼˜åŠ¿ï¼ŒKNNç”šè‡³ä¸éœ€è¦è®­ç»ƒå°±å¯ä»¥å¾—åˆ°éå¸¸å¥½çš„åˆ†ç±»æ•ˆæœäº†ã€‚
åœ¨è®­ç»ƒé›†ä¸­æ•°æ®å’Œæ ‡ç­¾å·²çŸ¥çš„æƒ…å†µä¸‹ï¼Œè¾“å…¥æµ‹è¯•æ•°æ®ï¼Œå°†æµ‹è¯•æ•°æ®çš„ç‰¹å¾ä¸è®­ç»ƒé›†ä¸­å¯¹åº”çš„ç‰¹å¾è¿›è¡Œç›¸äº’æ¯”è¾ƒï¼Œæ‰¾åˆ°è®­ç»ƒé›†ä¸­ä¸ä¹‹æœ€ä¸ºç›¸ä¼¼çš„å‰Kä¸ªæ•°æ®ï¼Œåˆ™è¯¥æµ‹è¯•æ•°æ®å¯¹åº”çš„ç±»åˆ«å°±æ˜¯Kä¸ªæ•°æ®ä¸­å‡ºç°æ¬¡æ•°æœ€å¤šçš„é‚£ä¸ªåˆ†ç±»ã€‚

å…¶ç®—æ³•çš„æè¿°ä¸ºï¼š
1.è®¡ç®—æµ‹è¯•æ•°æ®ä¸å„ä¸ªè®­ç»ƒæ•°æ®ä¹‹é—´çš„è·ç¦»ï¼›
2.æŒ‰ç…§è·ç¦»çš„é€’å¢å…³ç³»è¿›è¡Œæ’åºï¼›
3.é€‰å–è·ç¦»æœ€å°çš„Kä¸ªç‚¹ï¼›
4.ç¡®å®šå‰Kä¸ªç‚¹æ‰€åœ¨ç±»åˆ«çš„å‡ºç°é¢‘ç‡ï¼›
5.è¿”å›å‰Kä¸ªç‚¹ä¸­å‡ºç°é¢‘ç‡æœ€é«˜çš„ç±»åˆ«ä½œä¸ºæµ‹è¯•æ•°æ®çš„é¢„æµ‹åˆ†ç±»ã€‚
(æ„Ÿè§‰åˆè¯´å¤šäº†...... - -!)
å…¶å®è¿™ä¸ªç®—æ³•è‡ªå·±å®ç°èµ·æ¥ä¹Ÿå°±åªæœ‰å‡ è¡Œä»£ç ï¼Œè¿™é‡Œæˆ‘ä»¬è¿˜æ˜¯ä½¿ç”¨sklearnæ¥å®ç°ã€‚
sklearnä¸­çš„KNNå¯ä»¥åšåˆ†ç±»ä¹Ÿå¯ä»¥åšå›å½’

```python
# -*- coding: utf-8 -*-
"""
Created on Thu Apr 25 10:44:43 2019

@author: zangz
"""
import numpy as np
#ä»sklearnä¸­å€’å…¥æ•°æ®é›†
from sklearn import datasets 
#åˆ‡åˆ†è®­ç»ƒé›†æµ‹è¯•é›†çš„æ¨¡å—
#from sklearn.cross_validation import train_test_split 
from sklearn.model_selection import train_test_split 
#å¯¼å…¥KNNçš„åŒ…
import sklearn.neighbors as sk_neighbors

#ä½¿ç”¨çš„é¸¢å°¾èŠ±çš„æ•°æ®é›†
iris =datasets.load_iris()  
iris_X=iris.data  #æ•°æ®çš„ç‰¹å¾(4ä¸ªå±æ€§)
iris_Y=iris.target#æ•°æ®çš„æ ‡ç­¾(3ä¸ªåˆ†ç±»,0,1,2)

#æ•°æ®çš„åˆ‡å‰²(7:3),æ•°æ®ä¼šè¢«æ‰“ä¹±
X_train,X_test,y_train,y_test=train_test_split(iris_X,iris_Y,test_size=0.3)

#KNNåˆ†ç±»æ¨¡å‹
model = sk_neighbors.KNeighborsClassifier(n_neighbors=5,n_jobs=1) 
model.fit(X_train,y_train)
acc=model.score(X_test,y_test) #æ ¹æ®ç»™å®šæ•°æ®ä¸æ ‡ç­¾è¿”å›æ­£ç¡®ç‡çš„å‡å€¼
print('KNNæ¨¡å‹(åˆ†ç±»)è¯„ä»·:',acc)
new_X=([[1,2,5,9]])  #äºŒç»´
print(model.predict(new_X)) #æ‰“å°é¢„æµ‹çš„ç»“æœ

#KNNå›å½’æ¨¡å‹
model = sk_neighbors.KNeighborsRegressor(n_neighbors=5,n_jobs=1) 
model.fit(X_train,y_train)
acc=model.score(X_test,y_test) #è¿”å›é¢„æµ‹çš„ç¡®å®šç³»æ•°R2
print('KNNæ¨¡å‹(å›å½’)è¯„ä»·:',acc)


```

å‚æ•°è¯´æ˜ï¼š
n_neighborsï¼š ä½¿ç”¨é‚»å±…çš„æ•°ç›®
n_jobsï¼šå¹¶è¡Œä»»åŠ¡æ•°

æ‰“å°ç»“æœï¼š

```python
KNNæ¨¡å‹(åˆ†ç±»)è¯„ä»·: 0.9777777777777777
[2]
KNNæ¨¡å‹(å›å½’)è¯„ä»·: 0.9710843373493976

```

## äº¤å‰éªŒè¯

å¥½çš„ï¼Œç»ˆäºè¯´å®Œäº†å¸¸ç”¨æ¨¡å‹ï¼Œæ„Ÿè§‰å®Œå…¨æ˜¯ä¸€ä¸ªç®—æ³•æ¦‚è¿°å•Šhhhhh
æ—¢ç„¶æˆ‘ä»¬ç°åœ¨å·²ç»å®Œæˆäº†æ•°æ®çš„è·å–ï¼Œæ¨¡å‹çš„å»ºç«‹ï¼Œé‚£ä¹ˆæœ€åä¸€æ­¥ä¾¿æ˜¯éªŒè¯æˆ‘ä»¬çš„æ¨¡å‹
å…¶å®äº¤å‰éªŒè¯åº”è¯¥æ”¾åœ¨æ•°æ®é›†çš„åˆ’åˆ†é‚£é‡Œï¼Œä½†æ˜¯ä»–åˆä¸æ¨¡å‹çš„éªŒè¯ç´§å¯†ç›¸å…³ï¼Œæ‰€ä»¥æˆ‘å°±æŒ‰ç…§ç¼–å†™ä»£ç çš„é¡ºåºè¿›è¡Œè®²è§£äº†ã€‚
é¦–å…ˆï¼Œä»€ä¹ˆæ˜¯äº¤å‰éªŒè¯ï¼Ÿ
è¿™é‡Œå®Œå…¨å¼•ç”¨è¥¿ç“œä¹¦ï¼Œå› ä¸ºæˆ‘è§‰å¾—ä¹¦ä¸Šå†™çš„éå¸¸æ¸…æ¥šï¼ï¼ï¼
äº¤å‰éªŒè¯æ³•å…ˆå°†æ•°æ®é›†Dåˆ’åˆ†ä¸ºkä¸ªå¤§å°ç›¸ä¼¼çš„äº’æ–¥å­é›†ï¼Œæ¯ä¸ªå­é›†Diéƒ½å°½å¯èƒ½ä¿æŒæ•°æ®åˆ†å¸ƒçš„ä¸€è‡´æ€§ï¼Œå³ä»Dä¸­é€šè¿‡åˆ†å±‚é‡‡æ ·å¾—åˆ°ã€‚ç„¶åæ¯æ¬¡ç”¨k-1ä¸ªå­é›†çš„å¹¶é›†åšä¸ºè®­ç»ƒé›†ï¼Œä½™ä¸‹çš„å­é›†åšä¸ºæµ‹è¯•é›†ï¼Œè¿™æ ·å°±å¯ä»¥è·å¾—Kç»„è®­ç»ƒ/æµ‹è¯•é›†ï¼Œä»è€Œå¯ä»¥è¿›è¡Œkæ¬¡è®­ç»ƒå’Œæµ‹è¯•ï¼Œæœ€ç»ˆè¿”å›çš„æ˜¯è¿™ä¸ªkä¸ªæµ‹è¯•ç»“æœçš„å‡å€¼ã€‚ké€šå¸¸çš„å–å€¼æ˜¯10ï¼Œå…¶ä»–å¸¸ç”¨å–å€¼ä¸º2ï¼Œ5ï¼Œ20ç­‰ã€‚
![äº¤å‰éªŒè¯æ•°æ®é›†çš„æ‹†åˆ†](https://upload-images.jianshu.io/upload_images/14555448-9b0d96068f269251.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

è¿™é‡Œä½¿ç”¨KNNåšä¸ºè®­ç»ƒæ¨¡å‹ï¼Œé‡‡ç”¨åæŠ˜äº¤å‰éªŒè¯ã€‚

```
# -*- coding: utf-8 -*-
"""
Created on Thu Apr 25 10:44:43 2019

@author: zangz
"""
import numpy as np
#ä»sklearnä¸­å€’å…¥æ•°æ®é›†
from sklearn import datasets 
#åˆ‡åˆ†è®­ç»ƒé›†æµ‹è¯•é›†çš„æ¨¡å—
#from sklearn.cross_validation import train_test_split 
from sklearn.model_selection import train_test_split 
#å¯¼å…¥KNNçš„åŒ…
import sklearn.neighbors as sk_neighbors
#å¯¼å…¥äº¤å‰éªŒè¯çš„åŒ…
import sklearn.model_selection as sk_model_selection

#ä½¿ç”¨çš„é¸¢å°¾èŠ±çš„æ•°æ®é›†
iris =datasets.load_iris()  
iris_X=iris.data  #æ•°æ®çš„ç‰¹å¾(4ä¸ªå±æ€§)
iris_Y=iris.target#æ•°æ®çš„æ ‡ç­¾(3ä¸ªåˆ†ç±»,0,1,2)
#åˆ›å»ºæ¨¡å‹
model = sk_neighbors.KNeighborsClassifier(n_neighbors=5,n_jobs=1) #KNNåˆ†ç±»
#è¿›è¡Œäº¤å‰éªŒè¯
accs=sk_model_selection.cross_val_score(model, iris_X, y=iris_Y, scoring=None,cv=10, n_jobs=1)
print('äº¤å‰éªŒè¯ç»“æœ:',accs)

```

å‚æ•°è¯´æ˜ï¼š
modelï¼šæ‹Ÿåˆæ•°æ®çš„æ¨¡å‹
cv ï¼š å­é›†ä¸ªæ•° å°±æ˜¯k
scoring: æ‰“åˆ†å‚æ•° é»˜è®¤â€˜accuracyâ€™ã€å¯é€‰â€˜f1â€™ã€â€˜precisionâ€™ã€â€˜recallâ€™ ã€â€˜roc_aucâ€™ã€'neg_log_loss'

æ‰“å°ç»“æœï¼š

```
äº¤å‰éªŒè¯ç»“æœ:
 [ 1.          0.93333333  1.          1.          0.86666667  0.93333333
  0.93333333  1.          1.          1.        ]

```

## æ¨¡å‹çš„ä¿å­˜å’Œè½½å…¥

æ¨¡å‹çš„ä¿å­˜å’Œè½½å…¥æ–¹ä¾¿æˆ‘ä»¬å°†è®­ç»ƒå¥½çš„æ¨¡å‹ä¿å­˜åœ¨æœ¬åœ°æˆ–å‘é€åœ¨ç½‘ä¸Šï¼Œè½½å…¥æ¨¡å‹æ–¹ä¾¿æˆ‘ä»¬åœ¨ä¸åŒçš„ç¯å¢ƒä¸‹è¿›è¡Œæµ‹è¯•ã€‚
ä½¿ç”¨pickleå¯ä»¥è¿›è¡Œä¿å­˜ä¸è½½å…¥
ä¹Ÿå¯ä»¥ä½¿ç”¨sklearnè‡ªå¸¦çš„å‡½æ•°

```
import sklearn.externals as sk_externals
sk_externals.joblib.dump(model,'model.pickle') #ä¿å­˜
model = sk_externals.joblib.load('model.pickle') #è½½å…¥

```
å‚è€ƒç®€ä¹¦:https://www.jianshu.com/p/731610dca805
